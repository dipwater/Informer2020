{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IM6CZzW_CH0"
   },
   "source": "# Informer Train"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIjZdN5e_SWe"
   },
   "source": [
    "## Experiments: Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RPdt-Kwc_RRZ",
    "ExecuteTime": {
     "end_time": "2025-10-31T16:01:55.384911Z",
     "start_time": "2025-10-31T16:01:44.455015Z"
    }
   },
   "source": [
    "from utils.tools import dotdict\n",
    "from exp.exp_informer import Exp_Informer\n",
    "\n",
    "import torch\n",
    "\n",
    "print(\"PyTorch 版本:\", torch.__version__)\n",
    "print(\"CUDA 是否可用:\", torch.cuda.is_available())\n",
    "print(\"CUDA 版本:\", torch.version.cuda)\n",
    "print(\"cuDNN 版本:\", torch.backends.cudnn.version())\n",
    "print(\"GPU 数量:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"当前 GPU:\", torch.cuda.get_device_name(0))\n",
    "# root_path = '/content/drive/MyDrive/data/FLEA'"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 版本: 2.5.1+cu121\n",
      "CUDA 是否可用: True\n",
      "CUDA 版本: 12.1\n",
      "cuDNN 版本: 90100\n",
      "GPU 数量: 1\n",
      "当前 GPU: NVIDIA GeForce RTX 3060 Ti\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# python -u run.py --model informer --data custom --root_path ./data/FLEA/ --data_path Normal.csv --features M --target \"Motor Y Voltage\" \\\n",
    "# --enc_in 7 --dec_in 7 --c_out 1 --seq_len 96 --label_len 48 --pred_len 24 --batch_size 32 --train_epochs 10 --patience 3 --itr 1 --checkpoints ./checkpoints/Normal/\n",
    "args = dotdict()\n",
    "\n",
    "args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n",
    "\n",
    "args.custom_name = 'Jam' # data\n",
    "args.data = 'custom' # data\n",
    "args.data_path = 'Normal.csv' # data file\n",
    "args.root_path = 'data/FLEA' # root path of data file\n",
    "args.features = 'S' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
    "args.target = 'Motor Y Voltage' # target feature in S or MS task\n",
    "args.freq = 's' # freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n",
    "args.checkpoints = 'checkpoints' # location of model checkpoints\n",
    "\n",
    "args.seq_len = 200 # input sequence length of Informer encoder\n",
    "args.label_len = 30 # start token length of Informer decoder\n",
    "args.pred_len = 30 # prediction sequence length\n",
    "# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n",
    "args.batch_size = 32\n",
    "args.train_epochs = 6\n",
    "args.patience = 3\n",
    "args.itr = 1\n",
    "args.enc_in = 7 # encoder input size\n",
    "args.dec_in = 7 # decoder input size\n",
    "args.c_out = 1 # output size\n",
    "\n",
    "args.factor = 5 # probsparse attn factor\n",
    "args.d_model = 512 # dimension of model\n",
    "args.n_heads = 8 # num of heads\n",
    "args.e_layers = 2 # num of encoder layers\n",
    "args.d_layers = 1 # num of decoder layers\n",
    "args.d_ff = 2048 # dimension of fcn in model\n",
    "args.dropout = 0.05 # dropout\n",
    "args.attn = 'prob' # attention used in encoder, options:[prob, full]\n",
    "args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n",
    "args.activation = 'gelu' # activation\n",
    "args.distil = True # whether to use distilling in encoder\n",
    "args.output_attention = False # whether to output attention in ecoder\n",
    "args.mix = True\n",
    "args.padding = 0\n",
    "args.do_predict = True\n",
    "\n",
    "args.learning_rate = 0.0001\n",
    "args.loss = 'mse'\n",
    "args.lradj = 'type1'\n",
    "args.use_amp = False # whether to use automatic mixed precision training\n",
    "\n",
    "args.num_workers = 0\n",
    "args.des = 'exp'\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() else False\n",
    "args.gpu = 0\n",
    "\n",
    "args.use_multi_gpu = False\n",
    "args.devices = '0,1,2,3'\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k_BCYODAwKl9"
   },
   "source": [
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.devices = args.devices.replace(' ','')\n",
    "    device_ids = args.devices.split(',')\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "53o3pZ809p-a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1e5d2726-a033-41cd-82d4-fb27de38655f"
   },
   "source": [
    "# Set augments by using data name\n",
    "data_parser = {\n",
    "    'Normal':{'data':'Normal.csv','T':'Motor Y Voltage','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "    'Jam':{'data':'Jam.csv','T':'Motor Y Voltage','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "    'Position':{'data':'Position.csv','T':'Motor Y Voltage','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "    'Spall':{'data':'Spall.csv','T':'Motor Y Voltage','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "}\n",
    "print(args.custom_name)\n",
    "if args.custom_name in data_parser.keys():\n",
    "    data_info = data_parser[args.custom_name]\n",
    "    args.data_path = data_info['data']\n",
    "    args.target = data_info['T']\n",
    "    print(data_info[args.features])\n",
    "    args.enc_in, args.dec_in, args.c_out = data_info[args.features]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yZ5Q2vyKwSfk"
   },
   "source": [
    "args.detail_freq = args.freq\n",
    "args.freq = args.freq[-1:]\n",
    "\n",
    "print('Args in experiment:')\n",
    "print(args)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KVHZhRB4-on9"
   },
   "source": [
    "Exp = Exp_Informer"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "928tzaA2AA2g",
    "outputId": "5f6b9d7e-0d78-4061-d84d-ec23548e84d7"
   },
   "source": [
    "for ii in range(args.itr):\n",
    "    # setting record of experiments\n",
    "    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data_path.replace('.csv', ''), args.features,\n",
    "                args.seq_len, args.label_len, args.pred_len,\n",
    "                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n",
    "\n",
    "    exp = Exp(args) # set experiments\n",
    "    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "    exp.train(setting)\n",
    "\n",
    "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "    exp.test(setting)\n",
    "\n",
    "    if args.do_predict:\n",
    "        print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "        exp.predict(setting, True)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "print(\"train finish\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "ImH1fIDCTdQO"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDHF-HerAE3u"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KBCPbjGuzAZb",
    "outputId": "450355df-3d65-444b-9e9e-8bd89db13533"
   },
   "source": [
    "# the prediction will be saved in ./results/{setting}/real_prediction.npy\n",
    "import numpy as np\n",
    "\n",
    "#setting = 'informer_custom_ftMS_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_0'\n",
    "prediction = np.load('./results/'+setting+'/real_prediction.npy')\n",
    "\n",
    "prediction.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yFuVkTV30_j"
   },
   "source": [
    "### More details about Prediction - prediction function"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Sv9AR_Aw030r"
   },
   "source": [
    "# here is the detailed code of function predict\n",
    "\n",
    "def predict(exp, setting, load=False):\n",
    "    pred_data, pred_loader = exp._get_data(flag='pred')\n",
    "\n",
    "    if load:\n",
    "        path = os.path.join(exp.args.checkpoints, setting)\n",
    "        best_model_path = path+'/'+'checkpoint.pth'\n",
    "        exp.model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "    exp.model.eval()\n",
    "\n",
    "    preds = []\n",
    "\n",
    "    for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(pred_loader):\n",
    "        batch_x = batch_x.float().to(exp.device)\n",
    "        batch_y = batch_y.float()\n",
    "        batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "        batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "\n",
    "        # decoder input\n",
    "        if exp.args.padding==0:\n",
    "            dec_inp = torch.zeros([batch_y.shape[0], exp.args.pred_len, batch_y.shape[-1]]).float()\n",
    "        elif exp.args.padding==1:\n",
    "            dec_inp = torch.ones([batch_y.shape[0], exp.args.pred_len, batch_y.shape[-1]]).float()\n",
    "        else:\n",
    "            dec_inp = torch.zeros([batch_y.shape[0], exp.args.pred_len, batch_y.shape[-1]]).float()\n",
    "        dec_inp = torch.cat([batch_y[:,:exp.args.label_len,:], dec_inp], dim=1).float().to(exp.device)\n",
    "        # encoder - decoder\n",
    "        if exp.args.use_amp:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                if exp.args.output_attention:\n",
    "                    outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                else:\n",
    "                    outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "        else:\n",
    "            if exp.args.output_attention:\n",
    "                outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "            else:\n",
    "                outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "        f_dim = -1 if exp.args.features=='MS' else 0\n",
    "        batch_y = batch_y[:,-exp.args.pred_len:,f_dim:].to(exp.device)\n",
    "\n",
    "        pred = outputs.detach().cpu().numpy()#.squeeze()\n",
    "\n",
    "        preds.append(pred)\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "\n",
    "    # result save\n",
    "    folder_path = './results/' + setting +'/'\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    np.save(folder_path+'real_prediction.npy', preds)\n",
    "\n",
    "    return preds\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tVLWZL2a1pwB",
    "outputId": "a9cc35ff-0341-4ab6-adca-71be99b7a29f"
   },
   "source": [
    "# you can also use this prediction function to get result\n",
    "prediction = predict(exp, setting, True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "NwtZmQC71uc8",
    "outputId": "22925526-2379-41cd-c38f-be9d8e4b24a1"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(prediction[0,:,-1])\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnePVyrW4I14"
   },
   "source": [
    "### More details about Prediction - prediction dataset\n",
    "\n",
    "You can give a `root_path` and `data_path` of the data you want to forecast, and set `seq_len`, `label_len`, `pred_len` and other arguments as other Dataset. The difference is that you can set a more detailed freq such as `15min` or `3h` to generate the timestamp of prediction series.\n",
    "\n",
    "`Dataset_Pred` only has one sample (including `encoder_input: [1, seq_len, dim]`, `decoder_token: [1, label_len, dim]`, `encoder_input_timestamp: [1, seq_len, date_dim]`, `decoder_input_timstamp: [1, label_len+pred_len, date_dim]`). It will intercept the last sequence of the given data (seq_len data) to forecast the unseen future sequence (pred_len data)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZpXhNGp34Hf4"
   },
   "source": [
    "from data.data_loader import Dataset_Pred\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j4Rpd1q74T8N"
   },
   "source": [
    "Data = Dataset_Pred\n",
    "timeenc = 0 if args.embed!='timeF' else 1\n",
    "flag = 'pred'; shuffle_flag = False; drop_last = False; batch_size = 1\n",
    "\n",
    "freq = args.detail_freq\n",
    "\n",
    "data_set = Data(\n",
    "    root_path=args.root_path,\n",
    "    data_path=args.data_path,\n",
    "    flag=flag,\n",
    "    size=[args.seq_len, args.label_len, args.pred_len],\n",
    "    features=args.features,\n",
    "    target=args.target,\n",
    "    timeenc=timeenc,\n",
    "    freq=freq\n",
    ")\n",
    "data_loader = DataLoader(\n",
    "    data_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle_flag,\n",
    "    num_workers=args.num_workers,\n",
    "    drop_last=drop_last)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "42C84BfY6UPV",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fc45fbd2-d445-4b6b-a8d8-debebe8d994b"
   },
   "source": [
    "len(data_set), len(data_loader)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNhEP_7sAgqC"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vMRk8VkQ2Iko",
    "outputId": "ed60d592-946d-4433-a8fd-a13db4cbd5cf"
   },
   "source": [
    "# When we finished exp.train(setting) and exp.test(setting), we will get a trained model and the results of test experiment\n",
    "# The results of test experiment will be saved in ./results/{setting}/pred.npy (prediction of test dataset) and ./results/{setting}/true.npy (groundtruth of test dataset)\n",
    "\n",
    "preds = np.load('./results/'+setting+'/pred.npy')\n",
    "trues = np.load('./results/'+setting+'/true.npy')\n",
    "\n",
    "# [samples, pred_len, dimensions]\n",
    "preds.shape, trues.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZEGhDOmxAeAb"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "kyPuOPGAAjl3",
    "outputId": "a57e9238-37f4-4406-c9ff-3758efac0943"
   },
   "source": [
    "# draw OT prediction\n",
    "plt.figure()\n",
    "plt.plot(trues[0,:,-1], label='GroundTruth')\n",
    "plt.plot(preds[0,:,-1], label='Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "43MIgWfpMYIB",
    "outputId": "9d4faae0-5cf2-455f-8c29-1ac5a6955bd5"
   },
   "source": [
    "# draw HUFL prediction\n",
    "plt.figure()\n",
    "plt.plot(trues[0,:,0], label='GroundTruth')\n",
    "plt.plot(preds[0,:,0], label='Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hKmqhCfmt0xd"
   },
   "source": [
    "from data.data_loader import Dataset_ETT_hour\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "Data = Dataset_ETT_hour\n",
    "timeenc = 0 if args.embed!='timeF' else 1\n",
    "flag = 'test'; shuffle_flag = False; drop_last = True; batch_size = 1\n",
    "\n",
    "data_set = Data(\n",
    "    root_path=args.root_path,\n",
    "    data_path=args.data_path,\n",
    "    flag=flag,\n",
    "    size=[args.seq_len, args.label_len, args.pred_len],\n",
    "    features=args.features,\n",
    "    timeenc=timeenc,\n",
    "    freq=args.freq\n",
    ")\n",
    "data_loader = DataLoader(\n",
    "    data_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle_flag,\n",
    "    num_workers=args.num_workers,\n",
    "    drop_last=drop_last)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iflTTl0quCoK",
    "outputId": "5ca23cfa-1005-4678-ff0c-502d312d31e1"
   },
   "source": [
    "import os\n",
    "\n",
    "args.output_attention = True\n",
    "\n",
    "exp = Exp(args)\n",
    "\n",
    "model = exp.model\n",
    "\n",
    "setting = 'informer_custom_ftMS_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_0'\n",
    "path = os.path.join(args.checkpoints,setting,'checkpoint.pth')\n",
    "model.load_state_dict(torch.load(path))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lDdzqm9HAk2C"
   },
   "source": [
    "# attention visualization\n",
    "idx = 0\n",
    "for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(data_loader):\n",
    "    if i!=idx:\n",
    "        continue\n",
    "    batch_x = batch_x.float().to(exp.device)\n",
    "    batch_y = batch_y.float()\n",
    "\n",
    "    batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "    batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "\n",
    "    dec_inp = torch.zeros_like(batch_y[:,-args.pred_len:,:]).float()\n",
    "    dec_inp = torch.cat([batch_y[:,:args.label_len,:], dec_inp], dim=1).float().to(exp.device)\n",
    "\n",
    "    outputs,attn = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWef23vWAmUz",
    "outputId": "307b55ee-8311-4785-8194-5f60f1cf37c7"
   },
   "source": [
    "attn[0].shape, attn[1].shape #, attn[2].shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iZDH1fZgAnrl",
    "outputId": "78e21b37-7c8b-4653-e00a-2dd293ebe9ad"
   },
   "source": [
    "layer = 0\n",
    "distil = 'Distil' if args.distil else 'NoDistil'\n",
    "for h in range(0,8):\n",
    "    plt.figure(figsize=[10,8])\n",
    "    plt.title('Informer, {}, attn:{} layer:{} head:{}'.format(distil, args.attn, layer, h))\n",
    "    A = attn[layer][0,h].detach().cpu().numpy()\n",
    "    ax = sns.heatmap(A, vmin=0, vmax=A.max()+0.01)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DQFGYE3KAozo",
    "outputId": "03821981-818c-4143-a873-6884f380afb1"
   },
   "source": [
    "layer = 1\n",
    "distil = 'Distil' if args.distil else 'NoDistil'\n",
    "for h in range(0,8):\n",
    "    plt.figure(figsize=[10,8])\n",
    "    plt.title('Informer, {}, attn:{} layer:{} head:{}'.format(distil, args.attn, layer, h))\n",
    "    A = attn[layer][0,h].detach().cpu().numpy()\n",
    "    ax = sns.heatmap(A, vmin=0, vmax=A.max()+0.01)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ew9vekI9Mw8f"
   },
   "source": [
    "## Custom Data\n",
    "\n",
    "Custom data (xxx.csv) has to include at least 2 features: `date`(format: `YYYY-MM-DD hh:mm:ss`) and `target feature`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qqQBJWHeMzP-"
   },
   "source": [
    "from data.data_loader import Dataset_Custom\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5bFrfuw6Oxpi"
   },
   "source": [
    "# custom data: xxx.csv\n",
    "# data features: ['date', ...(other features), target feature]\n",
    "\n",
    "# we take Jam as an example\n",
    "args.root_path = 'Informer2020/data/FLEA/'\n",
    "args.data_path = 'Jam.csv'\n",
    "\n",
    "df = pd.read_csv(os.path.join(args.root_path, args.data_path))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0--9JC0eO_WT",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "outputId": "a7e33620-b1b2-4859-e3b9-47daac94afe9"
   },
   "source": [
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QmvRipRbPAbP"
   },
   "source": [
    "'''\n",
    "We set 'HULL' as target instead of 'OT'\n",
    "\n",
    "The following frequencies are supported:\n",
    "        Y   - yearly\n",
    "            alias: A\n",
    "        M   - monthly\n",
    "        W   - weekly\n",
    "        D   - daily\n",
    "        B   - business days\n",
    "        H   - hourly\n",
    "        T   - minutely\n",
    "            alias: min\n",
    "        S   - secondly\n",
    "'''\n",
    "\n",
    "args.target = 'Motor Y Voltage'\n",
    "args.freq = 'h'\n",
    "\n",
    "Data = Dataset_Custom\n",
    "timeenc = 0 if args.embed!='timeF' else 1\n",
    "flag = 'test'; shuffle_flag = False; drop_last = True; batch_size = 1\n",
    "\n",
    "data_set = Data(\n",
    "    root_path=args.root_path,\n",
    "    data_path=args.data_path,\n",
    "    flag=flag,\n",
    "    size=[args.seq_len, args.label_len, args.pred_len],\n",
    "    features=args.features,\n",
    "    timeenc=timeenc,\n",
    "    target=args.target, # HULL here\n",
    "    freq=args.freq # 'h': hourly, 't':minutely\n",
    ")\n",
    "data_loader = DataLoader(\n",
    "    data_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle_flag,\n",
    "    num_workers=args.num_workers,\n",
    "    drop_last=drop_last)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IkNDT2jMPCUf"
   },
   "source": [
    "batch_x,batch_y,batch_x_mark,batch_y_mark = data_set[0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VUcvSLlkSFTx"
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ]
}
