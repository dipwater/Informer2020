import numpy as np
import pandas as pd
import torch
import os
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler

# -------------------------------
# é…ç½®ï¼ˆè¯·æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´è·¯å¾„ï¼‰
# -------------------------------
# å…±åŒçš„æ ‡è¯†åç§°
PREFIX = 'Normal'
# æ¨¡å‹è·¯å¾„
MODEL_PATH = f'./checkpoints/informer_{PREFIX}_ftMS_sl500_ll50_pl50_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebfixed_dtTrue_mxTrue_Exp_fixed_2/checkpoint.pth'
# æ•°æ®è·¯å¾„
DATA_PATH = f'./data/FLEA/{PREFIX}.csv'
# è¾“å‡ºå›¾åƒä¿å­˜è·¯å¾„
OUTPUT_PLOT = f'./plots/prediction_{PREFIX}_multivariate.png'
# å›¾åƒæ ‡é¢˜
TITLE = f'{PREFIX} Multivariate Prediction Result'

DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')

SEQ_LEN = 500
LABEL_LEN = 50
PRED_LEN = 50
INPUT_DIM = 7   # 7ä¸ªè¾“å…¥ç‰¹å¾
OUTPUT_DIM = 1  # å•è¾“å‡º

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(os.path.dirname(OUTPUT_PLOT), exist_ok=True)

# -------------------------------
# 1. åŠ è½½æ•°æ®
# -------------------------------
print("ğŸš€ åŠ è½½æ•°æ®...")
df = pd.read_csv(DATA_PATH)

# è‡ªåŠ¨è¯†åˆ«ç‰¹å¾åˆ—ï¼ˆæ’é™¤ 'date'ï¼‰
cols = [col for col in df.columns if col != 'date']
if len(cols) != INPUT_DIM:
    raise ValueError(f"æœŸæœ› {INPUT_DIM} åˆ—ç‰¹å¾ï¼Œä½†å®é™…æœ‰ {len(cols)} åˆ—: {cols}")

target_col = 'Motor Y Voltage'
if target_col not in cols:
    raise ValueError(f"ç›®æ ‡åˆ— '{target_col}' ä¸åœ¨æ•°æ®ä¸­ï¼å¯ç”¨åˆ—: {cols}")

print(f"âœ… ç‰¹å¾åˆ—: {cols}")
print(f"ğŸ¯ ç›®æ ‡åˆ—: {target_col} (åº”ä¸ºæœ€åä¸€åˆ—)")

# æå–åŸå§‹æ•°æ®
raw_features = df[cols].values.astype(np.float32)          # (N, 7)
raw_target = df[target_col].values.reshape(-1, 1).astype(np.float32)  # (N, 1)

# -------------------------------
# 2. å½’ä¸€åŒ–ï¼ˆå…³é”®ï¼ï¼‰
# -------------------------------
# å¯¹æ‰€æœ‰è¾“å…¥ç‰¹å¾åˆ†åˆ«å½’ä¸€åŒ–ï¼ˆç”¨äºæ¨¡å‹è¾“å…¥ï¼‰
feature_scalers = {}
scaled_features = np.zeros_like(raw_features)
for i, col in enumerate(cols):
    scaler = MinMaxScaler()
    scaled_features[:, i:i+1] = scaler.fit_transform(raw_features[:, i:i+1])
    feature_scalers[col] = scaler

# âš ï¸ å¯¹ç›®æ ‡å˜é‡å•ç‹¬å½’ä¸€åŒ–ï¼ˆä»…ç”¨äºåå˜æ¢ï¼ï¼‰
target_scaler = MinMaxScaler()
target_scaler.fit(raw_target)  # â† å¿…é¡»ç”¨åŸå§‹å€¼ï¼

print("\nğŸ” å½’ä¸€åŒ–éªŒè¯:")
print(f"åŸå§‹ {target_col} èŒƒå›´: [{raw_target.min():.2f}, {raw_target.max():.2f}]")
print(f"Scaler è®°å½•èŒƒå›´: [{target_scaler.data_min_[0]:.2f}, {target_scaler.data_max_[0]:.2f}]")
assert np.isclose(target_scaler.data_min_[0], raw_target.min(), atol=1e-3), "Scaler èŒƒå›´ä¸åŒ¹é…ï¼"

# -------------------------------
# 3. æ„å»ºæ¨ç†æ•°æ®é›†
# -------------------------------
def create_dataset(X, Y, seq_len, label_len, pred_len, step=None):
    if step is None:
        step = pred_len
    Xs, Ys = [], []
    for i in range(0, len(X) - seq_len - pred_len + 1, step):
        Xs.append(X[i:i + seq_len])                          # (seq_len, 7)
        Ys.append(Y[i + seq_len : i + seq_len + pred_len, 0])  # (pred_len,)
    return np.array(Xs), np.array(Ys)

X_val, Y_true_raw = create_dataset(scaled_features, raw_target, SEQ_LEN, LABEL_LEN, PRED_LEN)
X_val = torch.tensor(X_val, dtype=torch.float32).to(DEVICE)
Y_true_raw = Y_true_raw  # ä¿ç•™åŸå§‹å€¼ç”¨äºå¯¹æ¯”ï¼ˆæœªå½’ä¸€åŒ–ï¼‰

print(f"\nğŸ“Š æ•°æ®é›†å½¢çŠ¶: X_val={X_val.shape}, Y_true_raw={Y_true_raw.shape}")

# -------------------------------
# 4. æ„é€  decoder è¾“å…¥ x_dec
# -------------------------------
B = X_val.shape[0]
dec_inp = torch.zeros(B, PRED_LEN, INPUT_DIM).to(DEVICE)
x_dec = torch.cat([X_val[:, -LABEL_LEN:, :], dec_inp], dim=1)  # (B, 100, 7)

# æ—¶é—´ç‰¹å¾ï¼ˆå ä½ï¼Œè‹¥æ¨¡å‹ä½¿ç”¨ï¼‰
x_mark_enc = torch.zeros(B, SEQ_LEN, 5, dtype=torch.long).to(DEVICE)
x_mark_dec = torch.zeros(B, LABEL_LEN + PRED_LEN, 5, dtype=torch.long).to(DEVICE)

# -------------------------------
# 5. åŠ è½½æ¨¡å‹
# -------------------------------
from models.model import Informer

model = Informer(
    enc_in=INPUT_DIM,
    dec_in=INPUT_DIM,
    c_out=OUTPUT_DIM,
    seq_len=SEQ_LEN,
    label_len=LABEL_LEN,
    pred_len=PRED_LEN,
    factor=5,
    d_model=512,
    n_heads=8,
    e_layers=2,
    d_layers=1,
    d_ff=2048,
    dropout=0.05,
    attn='prob',
    embed='fixed',
    freq='t',
    activation='gelu'
).to(DEVICE)

print("\nğŸ“¥ åŠ è½½æ¨¡å‹æƒé‡...")
state_dict = torch.load(MODEL_PATH, map_location=DEVICE, weights_only=True)
model.load_state_dict(state_dict)
model.eval()

# æ›¿æ¢åŸæ¥çš„æƒé‡æ£€æŸ¥éƒ¨åˆ†
print("\nğŸ“¥ åŠ è½½æ¨¡å‹æƒé‡...")
state_dict = torch.load(MODEL_PATH, map_location=DEVICE, weights_only=True)
model.load_state_dict(state_dict)
model.eval()

# âœ… é€šç”¨å‚æ•°æ£€æŸ¥ï¼ˆä¸å†ä¾èµ– .linearï¼‰
all_params = [p for p in model.parameters() if p.numel() > 0]
if not all_params:
    raise RuntimeError("æ¨¡å‹æ— æœ‰æ•ˆå‚æ•°ï¼")

first_param = all_params[0]
print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼é¦–ä¸ªå‚æ•°: mean={first_param.mean().item():.6f}, std={first_param.std().item():.6f}")

# -------------------------------
# 6. æ¨ç†
# -------------------------------
BATCH_SIZE = 32
preds_list = []

with torch.no_grad():
    for i in range(0, len(X_val), BATCH_SIZE):
        x_enc_batch = X_val[i:i+BATCH_SIZE]
        B_batch = x_enc_batch.shape[0]

        dec_inp_batch = torch.zeros(B_batch, PRED_LEN, INPUT_DIM).to(DEVICE)
        x_dec_batch = torch.cat([x_enc_batch[:, -LABEL_LEN:, :], dec_inp_batch], dim=1)

        x_mark_enc_batch = torch.zeros(B_batch, SEQ_LEN, 5, dtype=torch.long).to(DEVICE)
        x_mark_dec_batch = torch.zeros(B_batch, LABEL_LEN + PRED_LEN, 5, dtype=torch.long).to(DEVICE)

        pred = model(x_enc_batch, x_mark_enc_batch, x_dec_batch, x_mark_dec_batch)  # (B, 50, 1)
        preds_list.append(pred.cpu())

preds = torch.cat(preds_list, dim=0)  # (B, 50, 1)
preds = preds.squeeze(-1).numpy()     # (B, 50)

# å±•å¹³
pred_flat = preds.reshape(-1, 1)      # (B*50, 1)
true_flat = Y_true_raw.reshape(-1, 1) # (B*50, 1) â€”â€” æ³¨æ„ï¼šè¿™æ˜¯åŸå§‹å€¼ï¼

# -------------------------------
# 7. è°ƒè¯•è¾“å‡ºï¼ˆå…³é”®ï¼ï¼‰
# -------------------------------
print("\nğŸ” æ¨ç†ç»“æœè°ƒè¯•:")
print(f"æ¨¡å‹è¾“å‡ºï¼ˆå½’ä¸€åŒ–ï¼‰èŒƒå›´: [{pred_flat.min():.6f}, {pred_flat.max():.6f}]")
print(f"æ¨¡å‹è¾“å‡ºå‡å€¼: {pred_flat.mean():.6f}")

# åå½’ä¸€åŒ–é¢„æµ‹ç»“æœ
pred_original = target_scaler.inverse_transform(pred_flat)
print(f"åå½’ä¸€åŒ–åé¢„æµ‹èŒƒå›´: [{pred_original.min():.2f}, {pred_original.max():.2f}]")
print(f"çœŸå®å€¼èŒƒå›´: [{true_flat.min():.2f}, {true_flat.max():.2f}]")

# å¦‚æœé¢„æµ‹èŒƒå›´è¿œå°äºçœŸå®å€¼ â†’ æ¨¡å‹æ²¡å­¦å¥½ æˆ– scaler é”™è¯¯

# -------------------------------
# 8. ç»˜å›¾
# -------------------------------
N_SHOW = min(2000, len(pred_original))

plt.figure(figsize=(8, 6))
plt.plot(true_flat[:N_SHOW], label='True Value', color='#003f5c', linewidth=1.2)
plt.plot(pred_original[:N_SHOW], label='Predicted', color='#ffa600', linewidth=1.0, alpha=0.9)
plt.title(TITLE, fontsize=14)
plt.xlabel('Time Step')
plt.ylabel('Motor Y Voltage (V)')
plt.legend()
plt.grid(True, linestyle='--', alpha=0.5)
plt.tight_layout()
plt.savefig(OUTPUT_PLOT, dpi=300, bbox_inches='tight')
print(f"\nâœ… å›¾åƒå·²ä¿å­˜: {OUTPUT_PLOT}")
plt.show()

# -------------------------------
# 9. ä¿å­˜ CSV
# -------------------------------
result_df = pd.DataFrame({
    'True': true_flat[:N_SHOW].flatten(),
    'Predicted': pred_original[:N_SHOW].flatten()
})

OUTPUT_CSV = OUTPUT_PLOT.replace('.png', '.csv')
result_df.to_csv(OUTPUT_CSV, index=False)
print(f"âœ… CSV å·²ä¿å­˜: {OUTPUT_CSV}")

print("\nğŸ‰ æ¨ç†å®Œæˆï¼è¯·æ£€æŸ¥é¢„æµ‹èŒƒå›´æ˜¯å¦åˆç†ã€‚")