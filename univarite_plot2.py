# infer_informer_fixed.py

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
import os
from datetime import datetime

# -------------------------------
# 1. é…ç½®å‚æ•°
# -------------------------------
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# æ¨¡å‹è·¯å¾„
MODEL_PATH = './checkpoints/informer_Normal_ftS_sl500_ll50_pl50_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebfixed_dtTrue_mxTrue_Exp_fixed_500_2/checkpoint.pth'  # æ ¹æ®ä½ çš„å®é™…è·¯å¾„ä¿®æ”¹

# æ•°æ®è·¯å¾„
DATA_PATH = './data/FLEA/Normal.csv'

# æ¨¡å‹è¶…å‚æ•°ï¼ˆå¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
SEQ_LEN = 500      # è¾“å…¥åºåˆ—é•¿åº¦
LABEL_LEN = 50     # è§£ç å™¨å¼•å¯¼é•¿åº¦
PRED_LEN = 50      # é¢„æµ‹é•¿åº¦
INPUT_DIM = 1      # å•å˜é‡è¾“å…¥

# è¾“å‡ºå›¾åƒä¿å­˜è·¯å¾„
OUTPUT_PLOT = './plots/prediction_fixed_univariate.png'

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(os.path.dirname(OUTPUT_PLOT), exist_ok=True)

# -------------------------------
# 2. åŠ è½½å¹¶é¢„å¤„ç†æ•°æ®
# -------------------------------
print("ğŸš€ å¼€å§‹åŠ è½½æ•°æ®...")

# è¯»å–æ•°æ®
df = pd.read_csv(DATA_PATH)

# ç¡®ä¿ 'date' åˆ—æ˜¯æ—¶é—´ç±»å‹ï¼ˆä¿ç•™æ¯«ç§’ï¼‰
df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d %H:%M:%S.%f', errors='coerce')
# å¦‚æœæ ¼å¼ä¸ç»Ÿä¸€ï¼Œå¯ç”¨ï¼šdf['date'] = pd.to_datetime(df['date'])

# æ£€æŸ¥æ—¶é—´é—´éš”
time_diff = df['date'].diff().dropna().dt.total_seconds().unique()
print(f"æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰: {time_diff[:5]}")

# æå–ç›®æ ‡åˆ—
target_col = 'Motor Y Voltage'  # ä¿®æ”¹ä¸ºä½ çš„åˆ—å
if target_col not in df.columns:
    raise ValueError(f"åˆ— '{target_col}' ä¸å­˜åœ¨ï¼å¯ç”¨åˆ—: {list(df.columns)}")

raw_data = df[target_col].values.reshape(-1, 1).astype(np.float32)

# å½’ä¸€åŒ–
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(raw_data)  # (N, 1)

print(f"æ•°æ®å½¢çŠ¶: {scaled_data.shape}")
print(f"å½’ä¸€åŒ–èŒƒå›´: [{scaled_data.min():.4f}, {scaled_data.max():.4f}]")

# -------------------------------
# 3. æ„å»ºæµ‹è¯•é›†
# -------------------------------
def create_inference_dataset(data, seq_len, label_len, pred_len, step=None):
    """
    æ„å»ºæ»‘åŠ¨çª—å£æµ‹è¯•é›†
    """
    if step is None:
        step = pred_len  # é»˜è®¤æ­¥é•¿ä¸ºé¢„æµ‹é•¿åº¦

    X, Y = [], []
    for i in range(0, len(data) - seq_len - pred_len + 1, step):
        X.append(data[i:i + seq_len])  # (seq_len, 1)
        Y.append(data[i + seq_len : i + seq_len + pred_len, 0])  # (pred_len,)
    return np.array(X), np.array(Y)

print("ğŸ”§ æ„å»ºæµ‹è¯•é›†...")
X_val, Y_true = create_inference_dataset(
    scaled_data,
    seq_len=SEQ_LEN,
    label_len=LABEL_LEN,
    pred_len=PRED_LEN,
    step=PRED_LEN
)

X_val = torch.tensor(X_val, dtype=torch.float32).to(DEVICE)
Y_true = torch.tensor(Y_true, dtype=torch.float32).to(DEVICE)

print(f"X_val shape: {X_val.shape}")  # (B, 500, 1)
print(f"Y_true shape: {Y_true.shape}")  # (B, 50)

# -------------------------------
# 4. æ„é€ è§£ç å™¨è¾“å…¥ x_dec
# -------------------------------
B = X_val.shape[0]

# è§£ç å™¨è¾“å…¥ï¼šæœ€å LABEL_LEN ä¸ªçœŸå®å€¼ + PRED_LEN ä¸ª 0
dec_inp = torch.zeros(B, PRED_LEN, INPUT_DIM).to(DEVICE)
x_dec = torch.cat([X_val[:, -LABEL_LEN:, :], dec_inp], dim=1)  # (B, LABEL_LEN + PRED_LEN, 1)

print(f"x_dec shape: {x_dec.shape}")

# -------------------------------
# 5. åŠ è½½æ¨¡å‹ï¼ˆå‡è®¾æ¨¡å‹å®šä¹‰å·²å¯¼å…¥ï¼‰
# -------------------------------
# æ³¨æ„ï¼šä½ éœ€è¦ç¡®ä¿ Informer æ¨¡å‹ç±»å·²å®šä¹‰
# å¦‚æœä½ ä½¿ç”¨çš„æ˜¯å®˜æ–¹ä»£ç ï¼Œè¯·ç¡®ä¿å¯¼å…¥äº† model å’Œ configs

# ç”±äºæˆ‘ä»¬æ— æ³•ç›´æ¥å¯¼å…¥ main_informer ä¸­çš„æ¨¡å‹ï¼Œ
# è¿™é‡Œæˆ‘ä»¬å‡è®¾ä½ çŸ¥é“æ¨¡å‹ç»“æ„ï¼Œæ‰‹åŠ¨å®šä¹‰æˆ–ä»è®­ç»ƒä»£ç ä¸­å¤åˆ¶

from models.model import Informer  # æ ¹æ®ä½ çš„é¡¹ç›®ç»“æ„è°ƒæ•´è·¯å¾„

model = Informer(
    enc_in=INPUT_DIM,
    dec_in=INPUT_DIM,
    c_out=1,
    seq_len=SEQ_LEN,
    label_len=LABEL_LEN,
    pred_len=PRED_LEN,
    factor=5,
    d_model=512,
    n_heads=8,
    e_layers=2,
    d_layers=1,
    d_ff=2048,
    dropout=0.05,
    attn='prob',
    embed='fixed',           # âœ… å¿…é¡»ä¸è®­ç»ƒä¸€è‡´
    freq='t',                # ä»»æ„å€¼ï¼ˆfixed æ—¶æ— æ•ˆï¼‰
    activation='gelu'
).to(DEVICE)

# å®‰å…¨åŠ è½½æƒé‡
print("ğŸ“¥ åŠ è½½æ¨¡å‹æƒé‡...")
if os.path.exists(MODEL_PATH):
    state_dict = torch.load(MODEL_PATH, map_location=DEVICE, weights_only=True)
    model.load_state_dict(state_dict)
    print("âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸï¼")
else:
    raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {MODEL_PATH}")

model.eval()

# -------------------------------
# 6. æ¨ç†
# -------------------------------
print("ğŸ”® å¼€å§‹æ¨ç†...")

# âŒ é”™è¯¯ï¼šå…¨éƒ¨åŠ è½½
# X_val = torch.tensor(...).to(DEVICE)

# âœ… æ­£ç¡®ï¼šåˆ†æ‰¹æ¨ç†
BATCH_SIZE_INF = 4  # æ¯æ¬¡åªå¤„ç† 4 ä¸ªæ ·æœ¬

preds_list = []
trues_list = []

model.eval()
with torch.no_grad():
    for i in range(0, len(X_val), BATCH_SIZE_INF):
        x_enc_batch = X_val[i:i+BATCH_SIZE_INF].to(DEVICE)
        y_true_batch = Y_true[i:i+BATCH_SIZE_INF]

        # æ„é€  x_dec å’Œ x_markï¼ˆæ¯æ‰¹éƒ½æ„é€ ï¼‰
        B = x_enc_batch.shape[0]
        dec_inp = torch.zeros(B, PRED_LEN, INPUT_DIM).to(DEVICE)
        x_dec = torch.cat([x_enc_batch[:, -LABEL_LEN:, :], dec_inp], dim=1)

        x_mark_enc = torch.zeros(B, SEQ_LEN, 5, dtype=torch.long).to(DEVICE)
        x_mark_dec = torch.zeros(B, LABEL_LEN + PRED_LEN, 5, dtype=torch.long).to(DEVICE)

        pred = model(x_enc_batch, x_mark_enc, x_dec, x_mark_dec)  # (B, 50, 1)

        preds_list.append(pred.cpu())
        trues_list.append(y_true_batch.cpu())

# æ‹¼æ¥ç»“æœ
preds = torch.cat(preds_list, dim=0)
trues = torch.cat(trues_list, dim=0)

# ç§»åˆ° CPU å¹¶è½¬ä¸º numpy
preds = preds.cpu().numpy().reshape(-1)        # (B * 50,)
trues = Y_true.cpu().numpy().reshape(-1)       # (B * 50,)

# åå½’ä¸€åŒ–
preds = preds.reshape(-1, 1)
trues = trues.reshape(-1, 1)

pred_original = scaler.inverse_transform(preds).flatten()
true_original = scaler.inverse_transform(trues).flatten()

print(f"é¢„æµ‹æ•°æ®é•¿åº¦: {len(pred_original)}")
print(f"çœŸå®æ•°æ®é•¿åº¦: {len(true_original)}")

# -------------------------------
# 7. å¯è§†åŒ–ç»“æœï¼ˆä»…æ˜¾ç¤ºå‰ 2000 ç‚¹ï¼‰
# -------------------------------
print("ğŸ“Š ç»˜åˆ¶ç»“æœï¼ˆä»…å‰ 2000 ä¸ªç‚¹ï¼‰...")

N_SHOW = 2000
pred_plot = pred_original[:N_SHOW]
true_plot = true_original[:N_SHOW]

plt.figure(figsize=(16, 6))
plt.plot(true_plot, label='True Value', color='#003f5c', linewidth=2)
plt.plot(pred_plot, label='Predicted', color='#ffa600', linewidth=1.5, alpha=0.9)

plt.title('Informer Univariate Prediction Result', fontsize=16, pad=20)
plt.xlabel('Time Step (every 10ms)', fontsize=12)
plt.ylabel('Motor Y Voltage (V)', fontsize=12)
plt.legend(fontsize=12)
plt.grid(True, linestyle='--', alpha=0.5)
plt.tight_layout()

# ä¿å­˜å›¾åƒ
OUTPUT_PLOT = './plots/prediction_univariate.png'
plt.savefig(OUTPUT_PLOT, dpi=300, bbox_inches='tight')
print(f"âœ… å›¾åƒå·²ä¿å­˜è‡³: {OUTPUT_PLOT}")

plt.show()

# -------------------------------
# 8. ä¿å­˜é¢„æµ‹ç»“æœåˆ° CSVï¼ˆä»…å‰ 2000 è¡Œï¼‰
# -------------------------------
result_df = pd.DataFrame({
    'True': true_plot,
    'Predicted': pred_plot
})
result_csv = OUTPUT_PLOT.replace('.png', '.csv')
result_df.to_csv(result_csv, index=False)
print(f"âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜è‡³: {result_csv}")