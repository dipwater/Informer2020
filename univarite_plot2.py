# infer_informer_fixed.py

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
import os
from datetime import datetime

# -------------------------------
# 1. é…ç½®å‚æ•°
# -------------------------------
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# æ¨¡å‹è·¯å¾„
MODEL_PATH = './checkpoints/Exp_fixed_500/checkpoint.pth'  # æ ¹æ®ä½ çš„å®é™…è·¯å¾„ä¿®æ”¹

# æ•°æ®è·¯å¾„
DATA_PATH = './data/FLEA/Normal.csv'

# æ¨¡å‹è¶…å‚æ•°ï¼ˆå¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
SEQ_LEN = 500      # è¾“å…¥åºåˆ—é•¿åº¦
LABEL_LEN = 50     # è§£ç å™¨å¼•å¯¼é•¿åº¦
PRED_LEN = 50      # é¢„æµ‹é•¿åº¦
INPUT_DIM = 1      # å•å˜é‡è¾“å…¥

# è¾“å‡ºå›¾åƒä¿å­˜è·¯å¾„
OUTPUT_PLOT = './results/informer_prediction_fixed.png'

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(os.path.dirname(OUTPUT_PLOT), exist_ok=True)

# -------------------------------
# 2. åŠ è½½å¹¶é¢„å¤„ç†æ•°æ®
# -------------------------------
print("ğŸš€ å¼€å§‹åŠ è½½æ•°æ®...")

# è¯»å–æ•°æ®
df = pd.read_csv(DATA_PATH)

# ç¡®ä¿ 'date' åˆ—æ˜¯æ—¶é—´ç±»å‹ï¼ˆä¿ç•™æ¯«ç§’ï¼‰
df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d %H:%M:%S.%f', errors='coerce')
# å¦‚æœæ ¼å¼ä¸ç»Ÿä¸€ï¼Œå¯ç”¨ï¼šdf['date'] = pd.to_datetime(df['date'])

# æ£€æŸ¥æ—¶é—´é—´éš”
time_diff = df['date'].diff().dropna().dt.total_seconds().unique()
print(f"æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰: {time_diff[:5]}")

# æå–ç›®æ ‡åˆ—
target_col = 'Motor Y Voltage'  # ä¿®æ”¹ä¸ºä½ çš„åˆ—å
if target_col not in df.columns:
    raise ValueError(f"åˆ— '{target_col}' ä¸å­˜åœ¨ï¼å¯ç”¨åˆ—: {list(df.columns)}")

raw_data = df[target_col].values.reshape(-1, 1).astype(np.float32)

# å½’ä¸€åŒ–
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(raw_data)  # (N, 1)

print(f"æ•°æ®å½¢çŠ¶: {scaled_data.shape}")
print(f"å½’ä¸€åŒ–èŒƒå›´: [{scaled_data.min():.4f}, {scaled_data.max():.4f}]")

# -------------------------------
# 3. æ„å»ºæµ‹è¯•é›†
# -------------------------------
def create_inference_dataset(data, seq_len, label_len, pred_len, step=None):
    """
    æ„å»ºæ»‘åŠ¨çª—å£æµ‹è¯•é›†
    """
    if step is None:
        step = pred_len  # é»˜è®¤æ­¥é•¿ä¸ºé¢„æµ‹é•¿åº¦

    X, Y = [], []
    for i in range(0, len(data) - seq_len - pred_len + 1, step):
        X.append(data[i:i + seq_len])  # (seq_len, 1)
        Y.append(data[i + seq_len : i + seq_len + pred_len, 0])  # (pred_len,)
    return np.array(X), np.array(Y)

print("ğŸ”§ æ„å»ºæµ‹è¯•é›†...")
X_val, Y_true = create_inference_dataset(
    scaled_data,
    seq_len=SEQ_LEN,
    label_len=LABEL_LEN,
    pred_len=PRED_LEN,
    step=PRED_LEN
)

X_val = torch.tensor(X_val, dtype=torch.float32).to(DEVICE)
Y_true = torch.tensor(Y_true, dtype=torch.float32).to(DEVICE)

print(f"X_val shape: {X_val.shape}")  # (B, 500, 1)
print(f"Y_true shape: {Y_true.shape}")  # (B, 50)

# -------------------------------
# 4. æ„é€ è§£ç å™¨è¾“å…¥ x_dec
# -------------------------------
B = X_val.shape[0]

# è§£ç å™¨è¾“å…¥ï¼šæœ€å LABEL_LEN ä¸ªçœŸå®å€¼ + PRED_LEN ä¸ª 0
dec_inp = torch.zeros(B, PRED_LEN, INPUT_DIM).to(DEVICE)
x_dec = torch.cat([X_val[:, -LABEL_LEN:, :], dec_inp], dim=1)  # (B, LABEL_LEN + PRED_LEN, 1)

print(f"x_dec shape: {x_dec.shape}")

# -------------------------------
# 5. åŠ è½½æ¨¡å‹ï¼ˆå‡è®¾æ¨¡å‹å®šä¹‰å·²å¯¼å…¥ï¼‰
# -------------------------------
# æ³¨æ„ï¼šä½ éœ€è¦ç¡®ä¿ Informer æ¨¡å‹ç±»å·²å®šä¹‰
# å¦‚æœä½ ä½¿ç”¨çš„æ˜¯å®˜æ–¹ä»£ç ï¼Œè¯·ç¡®ä¿å¯¼å…¥äº† model å’Œ configs

# ç”±äºæˆ‘ä»¬æ— æ³•ç›´æ¥å¯¼å…¥ main_informer ä¸­çš„æ¨¡å‹ï¼Œ
# è¿™é‡Œæˆ‘ä»¬å‡è®¾ä½ çŸ¥é“æ¨¡å‹ç»“æ„ï¼Œæ‰‹åŠ¨å®šä¹‰æˆ–ä»è®­ç»ƒä»£ç ä¸­å¤åˆ¶

from models.model import Informer  # æ ¹æ®ä½ çš„é¡¹ç›®ç»“æ„è°ƒæ•´è·¯å¾„

model = Informer(
    enc_in=INPUT_DIM,
    dec_in=INPUT_DIM,
    c_out=1,
    seq_len=SEQ_LEN,
    label_len=LABEL_LEN,
    pred_len=PRED_LEN,
    factor=5,
    d_model=512,
    n_heads=8,
    e_layers=2,
    d_layers=1,
    d_ff=2048,
    dropout=0.05,
    attn='prob',
    embed='fixed',           # âœ… å¿…é¡»ä¸è®­ç»ƒä¸€è‡´
    freq='t',                # ä»»æ„å€¼ï¼ˆfixed æ—¶æ— æ•ˆï¼‰
    activation='gelu'
).to(DEVICE)

# å®‰å…¨åŠ è½½æƒé‡
print("ğŸ“¥ åŠ è½½æ¨¡å‹æƒé‡...")
if os.path.exists(MODEL_PATH):
    state_dict = torch.load(MODEL_PATH, map_location=DEVICE, weights_only=True)
    model.load_state_dict(state_dict)
    print("âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸï¼")
else:
    raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {MODEL_PATH}")

model.eval()

# -------------------------------
# 6. æ¨ç†
# -------------------------------
print("ğŸ”® å¼€å§‹æ¨ç†...")

with torch.no_grad():
    # âœ… å…³é”®ï¼šx_mark_enc å’Œ x_mark_dec ä¼  None
    preds = model(
        x_enc=X_val,           # (B, 500, 1)
        x_mark_enc=None,       # embed='fixed' æ—¶ä¸éœ€è¦
        x_dec=x_dec,           # (B, 100, 1)
        x_mark_dec=None        # ä¸éœ€è¦
    )  # è¾“å‡º: (B, 50, 1)

# ç§»åˆ° CPU å¹¶è½¬ä¸º numpy
preds = preds.cpu().numpy().reshape(-1)        # (B * 50,)
trues = Y_true.cpu().numpy().reshape(-1)       # (B * 50,)

# åå½’ä¸€åŒ–
preds = preds.reshape(-1, 1)
trues = trues.reshape(-1, 1)

pred_original = scaler.inverse_transform(preds).flatten()
true_original = scaler.inverse_transform(trues).flatten()

print(f"é¢„æµ‹æ•°æ®é•¿åº¦: {len(pred_original)}")
print(f"çœŸå®æ•°æ®é•¿åº¦: {len(true_original)}")

# -------------------------------
# 7. å¯è§†åŒ–ç»“æœ
# -------------------------------
print("ğŸ“Š ç»˜åˆ¶ç»“æœ...")

plt.figure(figsize=(16, 6))
plt.plot(true_original, label='True Value', color='#003f5c', linewidth=2)
plt.plot(pred_original, label='Predicted', color='#ffa600', linewidth=1.5, alpha=0.9)

plt.title('Informer Prediction Result (embed=fixed, 10ms Data)', fontsize=16, pad=20)
plt.xlabel('Time Step (every 10ms)', fontsize=12)
plt.ylabel('Motor Y Voltage (V)', fontsize=12)
plt.legend(fontsize=12)
plt.grid(True, linestyle='--', alpha=0.5)
plt.tight_layout()

# ä¿å­˜å›¾åƒ
plt.savefig(OUTPUT_PLOT, dpi=300, bbox_inches='tight')
print(f"âœ… å›¾åƒå·²ä¿å­˜è‡³: {OUTPUT_PLOT}")

plt.show()

# -------------------------------
# 8. å¯é€‰ï¼šä¿å­˜é¢„æµ‹ç»“æœåˆ° CSV
# -------------------------------
result_df = pd.DataFrame({
    'True': true_original,
    'Predicted': pred_original
})
result_csv = OUTPUT_PLOT.replace('.png', '.csv')
result_df.to_csv(result_csv, index=False)
print(f"âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜è‡³: {result_csv}")